Tipos de Datos Derivados
  Tipos homogéneos
    Tipo contiguo
    Tipo vector
    Tipo indexed
  Tipos heterogeneos
    Tipo struct


Proceso de Creación
  MPI_Datatype nuevoTipo
  MPI_TYPE_{vector, indexed, contiguous}(.., &nuevoTipo)
  MPI_Type_commit(&nuevoTipo)

  // Liberar la memoria
  MPI_Type_free(&nuevoTipo)

Tipos de Datos Derivados (DDs)
  Tipo contiguo
    MPI_Type_contiguous(count, oldtype, *newtype);

    p.ej/ -- ilustrativo, bastante poco util en este caso
      MPI_Type_contiguous(4, MPI_FLOAT, &nuevoTipo);
      MPI_Type_commit(&nuevoTipo);
      MPI_Send(&mat[4], 1, nuevoTipo, dest, tag, comm);

    p.ej/ -- struct
      typedef struct _particula{
        int x,y,z;
        int masa;
      } particula;

      particula p;

      MPI_Datatype particula_t;
      MPI_Type_contiguous(4, MPI_INT, &particula_t);
      MPI_Type_commit(&particula_t);

      MPI_Bcast(&p, 1, particula_t, 0, MPI_COMM_WORLD);

  Tipo vector
    MPI_Type_vector(count, blocklength, stride, oldtype, *newtype);

    p.ej/
      MPI_Type_vector(4, 1, 4, MPI_FLOAT, &nuevoTipo);
      MPI_Type_commit(&nuevoTipo);
      MPI_Send(&mat[1], 1, nuevoTipo, dest, tag, comm);

      [ o x o o ]
      [ o x o o ]
      [ o x o o ]
      [ o x o o ]

    caso general para tipoColumna
      MPI_Type_vector(n_filas, 1, n_columnas, MPI_FLOAT, &tipoColumna);

    variante
      MPI_Type_hvector( numero en bytes )

  Tipo indexed
    MPI_Type_indexed(count, blocklength[], offset[], oldtype, *newtype);
      ^^ 
    Tipo vector es un indexed con blocklength constante y offset constante (stride)

    p.ej/
      int lengths[] = {1,3,1,2};
      int offsets[] = {0,3,10,14};
      MPI_Type_indexed(4, lengths, offsets, MPI_FLOAT, &nuevoTipo);
      MPI_Type_commit(&nuevoTipo);
      MPI_Send(&mat[0], 1, nuevoTipo, dest, tag, comm);

    variante
     MPI_Type_hindexed( numero en bytes )

  Tipo struct
    MPI_Type_struct(count, blocklength[], offset[], old_types[], *newtype);

    p.ej/
      typedef struct _estructura{
        int a;
        double b,c;
        int d;
      } Estructura;

      Estructura e;

      MPI_Datatype tipo;

      int longitudes[] = {1,2,1}; // 1 int, 2 double, 1 int
      MPI_Aint offsets[3];
      MPI_Datatype viejos_tipos[] = {MPI_INT, MPI_DOUBLE, MPI_INT};
      
      MPI_Aint dir_a, dir_b, dir_d; // variables auxiliares
      MPI_Address(&(e.a), &dir_a);
      MPI_Address(&(e.b), &dir_b);
      MPI_Address(&(e.d), &dir_d);

      offsets[0] = 0; // distancia del primer bloque al primero
      offsets[1] = dir_b-dir_a; // distancia del segundo bloque al primero
      offsets[2] = dir_d - dir_a; // distancia del tercer bloque al primero
      
      MPI_Type_struct(3, longitudes, offsets, viejos_tipos, &tipo);
      MPI_Type_commit(&tipo);
      MPI_Bcast(&e, 1, tipo, 0, MPI_COMM_WORLD);


-------------------------------------------------------------------------------

MPI_Pack / Unpack

  char buffer [TAMBUFFER]; // TAMBUFFER se puede calcular con MPI_Pack_size
  int posicion = 0;

  int a;
  double b[200];
  float c[30];
  // queremos enviar todos en un mismo mensaje

  if(rank == 0){
    MPI_Pack(&a, 1, MPI_INT, buffer, TAMBUFFER, &posicion, MPI_COMM_WORLD);
    MPI_Pack(&b, 200, MPI_DOUBLE, buffer, TAMBUFFER, &posicion, MPI_COMM_WORLD);
    MPI_Pack(&c, 30, MPI_FLOAT, buffer, TAMBUFFER, &posicion, MPI_COMM_WORLD);
  }

  MPI_Bcast(buffer, TAMBUFFER, MPI_PACKED, 0, MPI_COMM_WORLD);

  if(rank != 0){
    MPI_Unpack(buffer, TAMBUFFER, &posicion, &a, 1, MPI_INT, MPI_COMM_WORLD);
    MPI_Unpack(buffer, TAMBUFFER, &posicion, &b, 200, MPI_DOUBLE, MPI_COMM_WORLD);
    MPI_Unpack(buffer, TAMBUFFER, &posicion, &c, 30, MPI_FLOAT, MPI_COMM_WORLD);
  }


-------------------------------------------------------------------------------

COMUNICADORES

 -> Comunicador que hemos usado hasta el momento: MPI_COMM_WORLD

  MPI_Comm nuevoComm;

  MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *newcomm);
    -> crea un newcomm que indentifica subconjuntos de comm
    -> color identifica el grupo al que va cada proceso
    -> key identifica el rank del proceso en el nuevo grupo
      a. key identifica el orden, no es el número tal cual
      b. si tienen dos procesos mismo numero de key, mantienen el orden original

  MPI_Comm_rank(MPI_Comm  comm, int *rank);
    -> Devuelve el rank del proceso dentro de comm

  MPI_Comm_free(MPI_Comm *comm);

  p.ej/
  MPI_Comm parImparComm;
  int color = rank%2;
  int key = rank/2;
  MPI_Comm_split(MPI_COMM_WORLD, color, key, &parImparComm);
  // operaciones...
  MPI_Comm_free(&parImparComm);

  --- Qué pasa si ---
  MPI_Bcast(fdato, root=0, ---, parImparComm);
    -> Para los impares, el proceso con key [MPI_Comm_rank()] 0, hace Bcast al resto
    de procesos de su color dentro del comunicador parImparComm.
      0 -> 2, 4, 6
      1 -> 3, 5, 7
  
  
  MPI_Comm_create()
    en combinación con MPI_Comm_group, MPI_Group_incl / MPI_Group_excl y el tipo MPI_Group
    
    <--Q-->
    0 1 2 3 \
    4 5 6 7 / P

  Cómo crear comunicador fila y comunicador columna?
    MPI_Comm fila, columna;
    int my_rank, p, q;

    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);
    p = my_rank/Q; // esta Q es la que indicamos en el dibujo 9 líneas arriba
    q = my_rank%Q; // tambien podemos poner my_rank/P, pero es más elegante asi

    MPI_Comm_split(MPI_COMM_WORLD, p, q, &fila);
    MPI_Comm_split(MPI_COMM_WORLD, q, p, &columna);


  Para crear un comunicador con MPI_Comm_create():
    MPI_Group group_world;
    MPI_Group first_row_group;
    MPI_Comm  first_row_comm;
    int * process_ranks;

    // procesos en el nuevo comunicador
    process_ranks = malloc(q*sizeof(int));
    for(int l = 0; l < q; l++){
      process_ranks[l] = l;
    }

    // obtener el grupo subyacente a MPI_COMM_WORLD
    MPI_Comm_group(MPI_COMM_WORLD, &group_world);

    // creamos el nuevo grupo
    MPI_Group_incl(group_world, q, process_ranks, &first_row_group);

    // crea el nuevo comunicador
    MPI_Comm_create(MPI_COMM_WORLD, first_row_group, &first_row_comm);

    /*********************************************\
    * MPI_COMM_WORLD               first_row_comm *
    *       v                            ^        *
    *  group_world -------------> first_row_group *
    \*********************************************/

    --- crear un comunicador con todos menos con la primer fila
    
    MPI_Comm_group(MPI_COMM_WORLD, &group_world);
    
    // creamos el grupo nuevo, excluyendo process_ranks
    MPI_Group_excl(group_world, q, process_ranks, &all_but_first_row_group);
    
    // creamos el comunicador
    MPI_Comm_create(MPI_COMM_WORLD, all_but_first_row_group, &all_but_first_row_comm);
        


-------------------------------------------------------------------------------

TOPOLOGÍÁS VIRTUALES

Topología cartensiana:
  MPI_Cart_create(MPI_Comm oldcomm, int ndims, int dims[], int periods[], int reorder, MPI_Comm *cartcomm);

  p.ej/
    o-o-o-o
    o-o-o-o
    o-o-o-o
    o-o-o-o   => 4x4                     Determina si se conservan los ranks o se reordenan (cambia el rank) [mapeo óptimo?]
                                                     v
    MPI_Cart_create(MPI_COMM_WORLD, 2, {4,4}, {0,0}, 0, fmalla);
                                              ^^^
                                     indica si hay wrap-around: si los procesos en los extremos, tienen vecinos (toro)

    // Devuelve las coordenadas cartesianas de el proceso actual
    MPI_Cart_get(MPI_Comm comm, int maxdims, int dims[], int periods[], int coords[]);

    // Coords to rank
    MPI_Cart_rank(MPI_Comm comm, int coords[], int *rank);

    // Rank to coords
    MPI_Cart_coords(MPI_Comm comm, int rango, int maxdims, int coords[]);

    // 
    MPI_Cart_shift(MPI_Comm comm, int direction, int despl, int *rank_origen, int *rank_destino)
      p.ej/
        MPI_Cart_shift(malla, 0, 1, &origen, &destino);
                              ^
                              |- 0 = x
                              |- 1 = y
                              |- _  etc...

        Devuelve despl a la izquierda y a la derecha. Si no hay proceso despl posiciones en origen o destino,
        devuelve MPI_PROC_NULL

    MPI_Dims_create(int nprocs, int ndims, int dims[]);

    --------

Subtopologías (virtuales)
  A partir de una malla podemos crear una subtopología fila
    -> o-o-o-o <-  fila
       o-o-o-o
       o-o-o-o
       o-o-o-o

    Crear dims: MPI_Dims_create(int nprocs, int ndims, int dims[]);

    Crear subtopologías virtuales: MPI_Cart_sub(MPI_Comm comm, int freedims[], MPI_Comm *newcomm);
      p.ej/
        MPI_Cart_sub(malla, {0,1}, &comm_fila);
                             ^^^
                  Numero de dimensiones: ignoro primera dimensión y cojo la segunda
                     -> a niveles efectivos, estoy creando subtopología fila (comunicador fila)

        MPI_Cart_sub(malla, {1,0}, &comm_columna);
  
  






